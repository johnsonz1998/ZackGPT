# ğŸ¤– Zachâ€™s Local Voice Assistant

A modular AI assistant with real voice interaction, memory, and personality â€” powered by OpenAI + ElevenLabs + Whisper.

---

## âœ¨ Features

- ğŸ™ï¸ **Voice input** via Whisper
- ğŸ”Š **Voice output** with ElevenLabs or macOS `say`
- ğŸ§  **Context-aware memory** using LlamaIndex + FAISS
- ğŸ’¬ **Custom assistant tone** (sarcastic, helpful, etc.)
- ğŸ§± **Modular agent system** (finance, calendar, etc.)
- âš¡ Built for speed, privacy, and local control

---

## ğŸ“¦ Project Structure
RAG/
â”œâ”€â”€ main.py # ğŸ§  Entry point
â”œâ”€â”€ config.py # Global settings and API keys
â”œâ”€â”€ memory_engine.py # Memory storage + recall
â”œâ”€â”€ logs/ # Chat memory logs
â”‚ â””â”€â”€ memory_log.jsonl
â”œâ”€â”€ data/ # Ingested reference documents
â”œâ”€â”€ embeddings/ # Vector index files
â”œâ”€â”€ assistants/ # Personality logic
â”‚ â””â”€â”€ core_assistant.py
â”œâ”€â”€ voice/ # Voice output modules
â”‚ â”œâ”€â”€ elevenlabs.py
â”‚ â””â”€â”€ tts_mac.py
â”œâ”€â”€ input/ # Whisper audio listener
â”‚ â””â”€â”€ whisper_listener.py
â”œâ”€â”€ llm/ # (optional) GPT logic
â”‚ â””â”€â”€ query_assistant.py
â”œâ”€â”€ tools/ # (optional) one-off scripts
â”‚ â””â”€â”€ ingest_text.py
â””â”€â”€ README.md


---

## ğŸ”§ Setup

1. **Install dependencies**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   brew install ffmpeg

In config,py configure API keys:

OPENAI_API_KEY = "sk-..."
ELEVENLABS_API_KEY = "sk-..."
ELEVENLABS_VOICE_ID = "..."

ğŸš€ Run the Assistant

python main.py

(Press Enter to talk. Say â€œquitâ€ or press Ctrl+C to exit.)

ğŸ§  Adding Knowledge
Drop .txt or .pdf files into /data
Then run: 

python tools/ingest_text.py

ğŸ§± Future Goals
ğŸ§  Long-term summarization & memory retention

ğŸ”„ Agent switching by domain (scheduler, analyst, etc.)

ğŸ“ Voice control via Twilio

ğŸ’¾ Local LLM fallback with Ollama or Mistral